"""
Conversation Engine Module
Agent conversationnel empathique
Supporte: Ollama (LOCAL), Groq (GRATUIT), Claude (payant), ou mode hors-ligne
"""

import os
from typing import List, Dict, Optional, Any
from dataclasses import dataclass
from datetime import datetime
import logging
import json
import requests

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class Message:
    """ReprÃ©sente un message dans la conversation"""
    role: str  # 'user' ou 'assistant'
    content: str
    emotion_context: Optional[str] = None
    timestamp: datetime = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.utcnow()
    
    def to_dict(self) -> Dict[str, str]:
        """Convertit en format API"""
        return {"role": self.role, "content": self.content}


# Traduction des Ã©motions en franÃ§ais pour le contexte
EMOTION_CONTEXT_FR = {
    "happy": "heureux/heureuse",
    "sad": "triste",
    "angry": "en colÃ¨re",
    "neutral": "calme",
    "surprise": "surpris(e)",
    "fear": "anxieux/anxieuse",
    "disgust": "dÃ©goÃ»tÃ©(e)"
}


class ConversationEngine:
    """
    Moteur de conversation empathique
    PrioritÃ©: Ollama (local) > Groq (gratuit) > Claude (payant)
    """
    
    # Prompt systÃ¨me pour l'assistant empathique
    SYSTEM_PROMPT = """Tu es un assistant IA empathique et bienveillant nommÃ© "Ã‰moji" ðŸ¤—.
    
Ton rÃ´le est d'accompagner l'utilisateur en fonction de son Ã©tat Ã©motionnel dÃ©tectÃ© par webcam.

## Tes caractÃ©ristiques :
- Tu parles en franÃ§ais de faÃ§on naturelle et chaleureuse
- Tu es attentif aux Ã©motions et tu adaptes ton ton
- Tu poses des questions ouvertes pour encourager l'expression
- Tu donnes des conseils bienveillants sans Ãªtre moralisateur
- Tu peux faire de l'humour lÃ©ger pour dÃ©tendre l'atmosphÃ¨re
- Tu encourages positivement sans Ãªtre condescendant

## Adaptation selon les Ã©motions :
- ðŸ˜Š HEUREUX : Partage la joie, renforce la positivitÃ©, cÃ©lÃ¨bre les moments
- ðŸ˜¢ TRISTE : Ã‰coute active, empathie profonde, soutien doux, suggÃ¨re des activitÃ©s rÃ©confortantes
- ðŸ˜  EN COLÃˆRE : Calme et apaisant, reconnais la frustration, propose des exercices de respiration
- ðŸ˜ NEUTRE : Engage la conversation, pose des questions intÃ©ressantes
- ðŸ˜² SURPRIS : CuriositÃ©, explore ce qui a causÃ© la surprise
- ðŸ˜¨ PEUR : Rassurant, prÃ©sence stable, techniques de relaxation
- ðŸ¤¢ DÃ‰GOÃ›T : ComprÃ©hension, change de sujet si nÃ©cessaire

## Format de tes rÃ©ponses :
- RÃ©ponses concises (2-4 phrases gÃ©nÃ©ralement)
- Utilise des emojis avec modÃ©ration
- Pose UNE question ouverte Ã  la fin quand c'est appropriÃ©
- Ne rÃ©pÃ¨te pas "Je vois que tu es [Ã©motion]" Ã  chaque message

## Exemples de rÃ©ponses :
- "Ã‡a fait plaisir de te voir sourire ! ðŸ˜Š Qu'est-ce qui te met de bonne humeur aujourd'hui ?"
- "Je sens que quelque chose te tracasse... Je suis lÃ  si tu veux en parler. ðŸ’™"
- "Prends une grande inspiration... voilÃ , doucement. Qu'est-ce qui t'a frustrÃ© ?"

Sois authentique, chaleureux et aide l'utilisateur Ã  se sentir Ã©coutÃ© et compris."""

    def __init__(self, api_key: Optional[str] = None):
        """
        Initialise le moteur de conversation
        DÃ©tecte automatiquement quelle API utiliser
        PrioritÃ©: Ollama (local) > Groq (gratuit) > Claude (payant)
        """
        # Configuration Ollama (local)
        self.ollama_url = os.getenv("OLLAMA_URL", "http://localhost:11434")
        self.ollama_model = os.getenv("OLLAMA_MODEL", "llama3.2")
        
        # Configuration Groq (gratuit)
        self.groq_api_key = os.getenv("GROQ_API_KEY")
        
        # Configuration Claude (payant)
        self.anthropic_api_key = api_key or os.getenv("ANTHROPIC_API_KEY")
        
        self.client = None
        self.api_type = None  # 'ollama', 'groq', 'anthropic', ou None
        self.conversation_history: List[Message] = []
        self.current_emotion: Optional[str] = None
        self.emotion_history: List[str] = []
        
        self._initialize_client()
    
    def _check_ollama_available(self) -> bool:
        """VÃ©rifie si Ollama est disponible localement"""
        try:
            response = requests.get(f"{self.ollama_url}/api/tags", timeout=2)
            return response.status_code == 200
        except:
            return False
    
    def _initialize_client(self):
        """Initialise le client API (Ollama prioritaire car local et gratuit)"""
        
        # 1. Essayer Ollama d'abord (LOCAL et GRATUIT)
        if self._check_ollama_available():
            self.api_type = 'ollama'
            logger.info(f"âœ… Ollama dÃ©tectÃ© ! ModÃ¨le: {self.ollama_model} (LOCAL)")
            return
        
        # 2. Essayer Groq ensuite (GRATUIT en ligne)
        if self.groq_api_key and self.groq_api_key != "your-groq-api-key-here":
            try:
                from groq import Groq
                self.client = Groq(api_key=self.groq_api_key)
                self.api_type = 'groq'
                logger.info("âœ… Client Groq API initialisÃ© (GRATUIT)")
                return
            except ImportError:
                logger.warning("âš ï¸ Module groq non installÃ©. Tapez: pip install groq")
            except Exception as e:
                logger.error(f"âŒ Erreur Groq: {e}")
        
        # 3. Essayer Claude ensuite (payant)
        if self.anthropic_api_key and self.anthropic_api_key != "your-anthropic-api-key-here":
            try:
                import anthropic
                self.client = anthropic.Anthropic(api_key=self.anthropic_api_key)
                self.api_type = 'anthropic'
                logger.info("âœ… Client Claude API initialisÃ©")
                return
            except ImportError:
                logger.warning("âš ï¸ Module anthropic non installÃ©")
            except Exception as e:
                logger.error(f"âŒ Erreur Claude API: {e}")
        
        # Mode hors-ligne
        logger.warning("âš ï¸ Aucune API configurÃ©e. Mode hors-ligne activÃ©.")
        logger.info("ðŸ’¡ Options: 1) Installez Ollama, 2) Ajoutez GROQ_API_KEY dans .env")
        self.api_type = None
    
    def set_emotion_context(self, emotion: str, confidence: float = 0.0):
        """
        Met Ã  jour le contexte Ã©motionnel
        
        Args:
            emotion: Ã‰motion dÃ©tectÃ©e (en anglais)
            confidence: Score de confiance
        """
        self.current_emotion = emotion
        self.emotion_history.append(emotion)
        
        # Garder seulement les 10 derniÃ¨res Ã©motions
        if len(self.emotion_history) > 10:
            self.emotion_history.pop(0)
    
    def _get_emotion_context_message(self) -> str:
        """GÃ©nÃ¨re le contexte Ã©motionnel pour le prompt"""
        if not self.current_emotion:
            return ""
        
        emotion_fr = EMOTION_CONTEXT_FR.get(self.current_emotion, self.current_emotion)
        
        # Analyser la tendance Ã©motionnelle
        trend_info = ""
        if len(self.emotion_history) >= 3:
            recent = self.emotion_history[-3:]
            if all(e == self.current_emotion for e in recent):
                trend_info = f" Cette Ã©motion semble persistante."
        
        return f"[Contexte Ã©motionnel: L'utilisateur semble {emotion_fr}.{trend_info}]"
    
    def generate_response(
        self, 
        user_message: str,
        emotion: Optional[str] = None,
        emotion_confidence: float = 0.0
    ) -> str:
        """
        GÃ©nÃ¨re une rÃ©ponse empathique basÃ©e sur le message et l'Ã©motion
        
        Args:
            user_message: Message de l'utilisateur
            emotion: Ã‰motion actuelle dÃ©tectÃ©e
            emotion_confidence: Confiance de la dÃ©tection
            
        Returns:
            RÃ©ponse de l'assistant
        """
        # Mettre Ã  jour le contexte Ã©motionnel
        if emotion:
            self.set_emotion_context(emotion, emotion_confidence)
        
        # Ajouter le message utilisateur Ã  l'historique
        self.conversation_history.append(Message(
            role="user",
            content=user_message,
            emotion_context=emotion
        ))
        
        # GÃ©nÃ©rer la rÃ©ponse selon l'API disponible
        if self.api_type == 'ollama':
            response = self._call_ollama_api(user_message)
        elif self.client and self.api_type == 'groq':
            response = self._call_groq_api(user_message)
        elif self.client and self.api_type == 'anthropic':
            response = self._call_claude_api(user_message)
        else:
            response = self._generate_fallback_response(user_message)
        
        # Ajouter la rÃ©ponse Ã  l'historique
        self.conversation_history.append(Message(
            role="assistant",
            content=response,
            emotion_context=emotion
        ))
        
        return response
    
    def _call_ollama_api(self, user_message: str) -> str:
        """Appelle l'API Ollama (LOCAL) pour gÃ©nÃ©rer une rÃ©ponse"""
        try:
            # Construire le contexte Ã©motionnel
            emotion_context = self._get_emotion_context_message()
            
            # PrÃ©parer les messages pour l'API
            messages = [{"role": "system", "content": self.SYSTEM_PROMPT}]
            
            # Ajouter l'historique rÃ©cent
            for i, msg in enumerate(self.conversation_history[-10:]):
                content = msg.content
                if i == len(self.conversation_history[-10:]) - 1 and emotion_context:
                    content = f"{emotion_context}\n\n{content}"
                messages.append({"role": msg.role, "content": content})
            
            # Appel API Ollama
            response = requests.post(
                f"{self.ollama_url}/api/chat",
                json={
                    "model": self.ollama_model,
                    "messages": messages,
                    "stream": False,
                    "options": {
                        "temperature": 0.7,
                        "num_predict": 500
                    }
                },
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                return result.get("message", {}).get("content", self._generate_fallback_response(user_message))
            else:
                logger.error(f"Erreur Ollama: {response.status_code}")
                return self._generate_fallback_response(user_message)
            
        except Exception as e:
            logger.error(f"Erreur API Ollama: {e}")
            return self._generate_fallback_response(user_message)
    
    def _call_groq_api(self, user_message: str) -> str:
        """Appelle l'API Groq (GRATUIT) pour gÃ©nÃ©rer une rÃ©ponse"""
        try:
            # Construire le contexte Ã©motionnel
            emotion_context = self._get_emotion_context_message()
            
            # PrÃ©parer les messages pour l'API
            messages = []
            
            # Ajouter l'historique rÃ©cent
            for i, msg in enumerate(self.conversation_history[-10:]):
                content = msg.content
                if i == len(self.conversation_history[-10:]) - 1 and emotion_context:
                    content = f"{emotion_context}\n\n{content}"
                messages.append({"role": msg.role, "content": content})
            
            # Appel API Groq
            response = self.client.chat.completions.create(
                model="llama-3.3-70b-versatile",  # ModÃ¨le gratuit et performant
                messages=[
                    {"role": "system", "content": self.SYSTEM_PROMPT},
                    *messages
                ],
                max_tokens=500,
                temperature=0.7
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"Erreur API Groq: {e}")
            return self._generate_fallback_response(user_message)
    
    def _call_claude_api(self, user_message: str) -> str:
        """Appelle l'API Claude pour gÃ©nÃ©rer une rÃ©ponse"""
        try:
            # Construire le contexte Ã©motionnel
            emotion_context = self._get_emotion_context_message()
            
            # PrÃ©parer les messages pour l'API
            messages = []
            
            # Ajouter le contexte Ã©motionnel au premier message si prÃ©sent
            for i, msg in enumerate(self.conversation_history[-10:]):  # Limiter l'historique
                content = msg.content
                if i == len(self.conversation_history[-10:]) - 1 and emotion_context:
                    # Ajouter le contexte au dernier message utilisateur
                    content = f"{emotion_context}\n\n{content}"
                messages.append({"role": msg.role, "content": content})
            
            # Appel API
            response = self.client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=500,
                system=self.SYSTEM_PROMPT,
                messages=messages
            )
            
            return response.content[0].text
            
        except Exception as e:
            logger.error(f"Erreur API Claude: {e}")
            return self._generate_fallback_response(user_message)
    
    def _generate_fallback_response(self, user_message: str) -> str:
        """
        GÃ©nÃ¨re une rÃ©ponse de secours si l'API n'est pas disponible
        RÃ©ponses prÃ©-dÃ©finies basÃ©es sur l'Ã©motion
        """
        emotion = self.current_emotion or "neutral"
        
        responses = {
            "happy": [
                "Ã‡a fait plaisir de te voir de bonne humeur ! ðŸ˜Š Qu'est-ce qui te rend si joyeux aujourd'hui ?",
                "Ton sourire est contagieux ! Continue comme Ã§a ! Raconte-moi ta journÃ©e ?",
                "Super ! J'adore cette Ã©nergie positive ! Qu'est-ce qui s'est passÃ© de bien ?"
            ],
            "sad": [
                "Je vois que tu traverses un moment difficile... Je suis lÃ  pour toi. ðŸ’™ Tu veux en parler ?",
                "C'est ok de ne pas aller bien parfois. Qu'est-ce qui te tracasse ?",
                "Je suis lÃ  pour t'Ã©couter, sans jugement. Prends ton temps pour me dire ce qui ne va pas."
            ],
            "angry": [
                "Je comprends que tu sois frustrÃ©(e). Prends une grande respiration... ðŸŒ¬ï¸ Qu'est-ce qui s'est passÃ© ?",
                "La colÃ¨re, c'est normal. Veux-tu en parler pour te libÃ©rer un peu ?",
                "Je t'Ã©coute. Parfois, exprimer ce qui nous Ã©nerve fait du bien."
            ],
            "neutral": [
                "Hey ! Comment vas-tu ? Qu'est-ce qui t'amÃ¨ne aujourd'hui ? ðŸ‘‹",
                "Coucou ! Je suis content de te voir. De quoi voudrais-tu parler ?",
                "Salut ! Comment se passe ta journÃ©e jusqu'ici ?"
            ],
            "fear": [
                "Je suis lÃ , tout va bien se passer. ðŸ¤— Qu'est-ce qui t'inquiÃ¨te ?",
                "Respire doucement... Je comprends que tu puisses te sentir anxieux. Parle-moi.",
                "Tu n'es pas seul(e). Dis-moi ce qui te fait peur, on peut en discuter ensemble."
            ],
            "surprise": [
                "Oh ! Tu as l'air surpris(e) ! Il s'est passÃ© quelque chose d'inattendu ?",
                "Wow, je vois la surprise sur ton visage ! Raconte-moi !",
                "Qu'est-ce qui t'a surpris comme Ã§a ? Je suis curieux !"
            ],
            "disgust": [
                "Hmm, quelque chose ne semble pas te plaire... Tu veux en parler ?",
                "Je vois que quelque chose te dÃ©range. Qu'est-ce qui s'est passÃ© ?",
                "On dirait que tu as vÃ©cu quelque chose de dÃ©sagrÃ©able. Je t'Ã©coute."
            ]
        }
        
        import random
        emotion_responses = responses.get(emotion, responses["neutral"])
        return random.choice(emotion_responses)
    
    def get_conversation_history(self) -> List[Dict[str, Any]]:
        """Retourne l'historique de conversation formatÃ©"""
        return [
            {
                "role": msg.role,
                "content": msg.content,
                "emotion": msg.emotion_context,
                "timestamp": msg.timestamp.isoformat() if msg.timestamp else None
            }
            for msg in self.conversation_history
        ]
    
    def clear_history(self):
        """Efface l'historique de conversation"""
        self.conversation_history.clear()
        self.emotion_history.clear()
        self.current_emotion = None
    
    def get_greeting(self, emotion: Optional[str] = None) -> str:
        """
        GÃ©nÃ¨re un message d'accueil personnalisÃ©
        
        Args:
            emotion: Ã‰motion initiale dÃ©tectÃ©e
            
        Returns:
            Message d'accueil
        """
        if emotion:
            self.set_emotion_context(emotion)
        
        greetings = {
            "happy": "Hey ! ðŸ˜Š Je vois que tu es de bonne humeur ! Ã‡a fait plaisir !",
            "sad": "Bonjour... ðŸ’™ Je suis lÃ  si tu as besoin de parler.",
            "angry": "Salut. Je vois que quelque chose te tracasse. Je t'Ã©coute.",
            "neutral": "Bonjour ! ðŸ‘‹ Comment puis-je t'aider aujourd'hui ?",
            "fear": "Coucou... ðŸ¤— Je suis lÃ , tout va bien. De quoi voudrais-tu parler ?",
            "surprise": "Oh ! Bonjour ! Tu as l'air surpris(e) de me voir ! ðŸ˜„",
            "disgust": "Salut... Quelque chose ne va pas ? Je suis lÃ  pour en parler."
        }
        
        return greetings.get(emotion or "neutral", greetings["neutral"])
    
    def generate_wellness_tip(self, emotion: str) -> str:
        """
        GÃ©nÃ¨re un conseil bien-Ãªtre basÃ© sur l'Ã©motion
        
        Args:
            emotion: Ã‰motion actuelle
            
        Returns:
            Conseil bien-Ãªtre
        """
        tips = {
            "happy": [
                "ðŸ’¡ Astuce : Note ce moment de bonheur dans un journal pour t'en souvenir !",
                "ðŸ’¡ Partage ta bonne humeur avec quelqu'un, la joie est contagieuse !",
                "ðŸ’¡ Profite de cette Ã©nergie pour faire quelque chose que tu aimes !"
            ],
            "sad": [
                "ðŸ’¡ Astuce : Une petite promenade Ã  l'air frais peut aider Ã  Ã©claircir les idÃ©es.",
                "ðŸ’¡ Ã‰coute une musique que tu aimes, Ã§a peut aider Ã  remonter le moral.",
                "ðŸ’¡ Prends un moment pour toi : un thÃ© chaud, une couverture, et du repos."
            ],
            "angry": [
                "ðŸ’¡ Astuce : Essaie la respiration 4-7-8 : inspire 4s, retiens 7s, expire 8s.",
                "ðŸ’¡ L'exercice physique aide Ã  Ã©vacuer la frustration. Une petite marche ?",
                "ðŸ’¡ Ã‰cris ce qui t'Ã©nerve sur un papier, puis froisse-le et jette-le !"
            ],
            "neutral": [
                "ðŸ’¡ C'est le moment parfait pour essayer quelque chose de nouveau !",
                "ðŸ’¡ Profite de ce calme pour planifier quelque chose qui te fait envie.",
                "ðŸ’¡ Un bon moment pour pratiquer la gratitude : 3 choses positives du jour ?"
            ],
            "fear": [
                "ðŸ’¡ Astuce : Ancre-toi dans le prÃ©sent - nomme 5 choses que tu vois autour de toi.",
                "ðŸ’¡ La respiration profonde active le systÃ¨me parasympathique et calme l'anxiÃ©tÃ©.",
                "ðŸ’¡ Rappelle-toi : 90% de nos inquiÃ©tudes ne se rÃ©alisent jamais."
            ]
        }
        
        import random
        emotion_tips = tips.get(emotion, tips["neutral"])
        return random.choice(emotion_tips)


# Instance globale pour utilisation simplifiÃ©e
_engine_instance: Optional[ConversationEngine] = None


def get_conversation_engine(api_key: Optional[str] = None) -> ConversationEngine:
    """Retourne l'instance singleton du moteur de conversation"""
    global _engine_instance
    if _engine_instance is None:
        _engine_instance = ConversationEngine(api_key)
    return _engine_instance


def reset_conversation_engine():
    """RÃ©initialise l'instance du moteur de conversation"""
    global _engine_instance
    if _engine_instance:
        _engine_instance.clear_history()
    _engine_instance = None
